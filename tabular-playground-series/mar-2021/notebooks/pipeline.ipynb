{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from optuna.integration import OptunaSearchCV\n",
    "from optuna.distributions import *\n",
    "import operator\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../src')\n",
    "from pipeline_utils import LGBMClassifierEarlyStopping, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "RANDOM_STATE = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 31)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883814</td>\n",
       "      <td>1.282606</td>\n",
       "      <td>0.450056</td>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.570031</td>\n",
       "      <td>1.106408</td>\n",
       "      <td>1.581648</td>\n",
       "      <td>2.364865</td>\n",
       "      <td>0.908369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>113</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.356673</td>\n",
       "      <td>0.039954</td>\n",
       "      <td>-0.137271</td>\n",
       "      <td>-0.464434</td>\n",
       "      <td>0.623672</td>\n",
       "      <td>-0.098985</td>\n",
       "      <td>-0.074612</td>\n",
       "      <td>1.923983</td>\n",
       "      <td>0.249945</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat0  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  ...     cont2  \\\n",
       "id                                                              ...             \n",
       "0      1     9     1     2     2   113     1    19    17     1  ...  0.883814   \n",
       "1      1     9     1     1     5   113    11    23    56     6  ... -0.356673   \n",
       "\n",
       "       cont3     cont4     cont5     cont6     cont7     cont8     cont9  \\\n",
       "id                                                                         \n",
       "0   1.282606  0.450056  0.332458  0.570031  1.106408  1.581648  2.364865   \n",
       "1   0.039954 -0.137271 -0.464434  0.623672 -0.098985 -0.074612  1.923983   \n",
       "\n",
       "      cont10  target  \n",
       "id                    \n",
       "0   0.908369       0  \n",
       "1   0.249945       0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{data_dir}/interim/train_for_David.csv\", index_col='id')\n",
    "# df = pd.read_parquet(f\"{data_dir}/interim/train.parq\", engine='pyarrow').convert_dtypes()\n",
    "display(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [col for col in df.columns if col.startswith('cont')]\n",
    "categorical_features = [col for col in df.columns if col.startswith('cat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    numeric_features = [col for col in df.columns if col.startswith('cont')]\n",
    "    categorical_features = [col for col in df.columns if col.startswith('cat')]\n",
    "    df[numeric_features] = df[numeric_features].astype('float')\n",
    "    df[categorical_features] = df[categorical_features].apply(lambda i: [sum(map(ord, x)) for x in i], axis='rows').astype('int')\n",
    "    df['gt_0.1'] = df[numeric_features].apply(lambda x: len([i for i in x if i > 0.1]), axis=1)\n",
    "    df['gt_0.5'] = df[numeric_features].apply(lambda x: len([i for i in x if i > 0.5]), axis=1)\n",
    "    df['mul_gt_o.1'] = 0\n",
    "    df.loc[(df['gt_0.1'] >=1), 'mul_gt_o.1'] = df[numeric_features].apply(lambda x: reduce(operator.mul, x), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['target'].astype('int')\n",
    "# df[categorical_features] = df[categorical_features].apply(lambda x: x.cat.codes).astype('int').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()\n",
    "y = X.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_engineering(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, train_size=0.8, test_size=0.2, random_state=RANDOM_STATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('log', FunctionTransformer(np.log1p)),\n",
    "    ('scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        output = []\n",
    "        for x in X:\n",
    "            output.append(LabelEncoder().fit_transform(x))\n",
    "        return np.array(output)\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X, y).transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "#     ('encoder', MultiColumnLabelEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess Pipeline   \n",
    "- merge cateogrical & numeric into one pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "          ('num', numeric_transformer, X.columns),\n",
    "#         ('cat', categorical_transformer, categorical_features),\n",
    "#         ('num', numeric_transformer, numeric_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline   \n",
    "- merge preprocess & model into one pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "#     ('preprocessor', preprocessor),\n",
    "    ('model', LGBMClassifier(\n",
    "#         categorical_feature=list(range(len(categorical_features))),\n",
    "#         early_stopping_rounds=300,\n",
    "#         test_size=0.2,\n",
    "#         eval_metric='auc',\n",
    "#         objective='binary',\n",
    "        random_state=RANDOM_STATE,\n",
    "    )),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for `OptunaSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "#     \"model__is_unbalance\": CategoricalDistribution([True, False]),\n",
    "    \"model__objective\": CategoricalDistribution([\"binary\"]),\n",
    "    \"model__metric\": CategoricalDistribution([\"auc\"]),\n",
    "    \"model__learning_rate\": LogUniformDistribution(1e-3, 1.0),\n",
    "    'model__n_estimators': CategoricalDistribution(range(2000, 5001, 500)),\n",
    "    'model__reg_alpha': LogUniformDistribution(1e-3, 10.0),\n",
    "    'model__reg_lambda': LogUniformDistribution(1e-3, 10.0),\n",
    "    'model__colsample_bytree': CategoricalDistribution(np.arange(0.1, 1.01, 0.1)),\n",
    "    'model__subsample': CategoricalDistribution(np.arange(0.1, 1.01, 0.1)),\n",
    "    'model__subsample_freq': IntUniformDistribution(1, 10),\n",
    "    'model__max_depth': IntUniformDistribution(1, 32),\n",
    "    'model__num_leaves' :  IntUniformDistribution(2, 256),\n",
    "    'model__min_child_samples': IntUniformDistribution(1, 256),\n",
    "    'model__cat_smooth' : IntUniformDistribution(1, 128),\n",
    "    'model__max_bin' : IntUniformDistribution(512, 2048),\n",
    "    'model__cat_l2': IntUniformDistribution(1, 32),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'model__is_unbalance': [False], 'model__objective': ['binary'], 'model__metric': ['auc'], 'model__learning_rate': [0.08], 'model__n_estimators': [4000], 'model__reg_alpha': [6.25], 'model__reg_lambda': [0.025], 'model__colsample_bytree': [0.2], 'model__subsample': [0.8], 'model__subsample_freq': [10], 'model__max_depth': [16], 'model__num_leaves': [128], 'model__min_child_samples': [100], 'model__cat_smooth': [88], 'model__max_bin': [666], 'model__cat_l2': [20]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\ipykernel_launcher.py:7: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "grid_search = OptunaSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=parameters,\n",
    "    cv=5,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    scoring=auc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass classifier=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n",
      "\u001b[32m[I 2021-03-11 22:21:36,979]\u001b[0m A new study created in memory with name: no-name-7dfbbf57-b113-4292-a545-7362e9a7804e\u001b[0m\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\u001b[32m[I 2021-03-11 22:58:27,968]\u001b[0m Trial 1 finished with value: 0.8931240338097627 and parameters: {'model__objective': 'binary', 'model__metric': 'auc', 'model__learning_rate': 0.0034807501074447154, 'model__n_estimators': 2000, 'model__reg_alpha': 0.11451044872325485, 'model__reg_lambda': 0.005873518790253586, 'model__colsample_bytree': 0.8, 'model__subsample': 0.30000000000000004, 'model__subsample_freq': 10, 'model__max_depth': 12, 'model__num_leaves': 106, 'model__min_child_samples': 242, 'model__cat_smooth': 54, 'model__max_bin': 525, 'model__cat_l2': 3}. Best is trial 1 with value: 0.8931240338097627.\u001b[0m\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\u001b[32m[I 2021-03-11 23:06:10,679]\u001b[0m Trial 0 finished with value: 0.8911587508293739 and parameters: {'model__objective': 'binary', 'model__metric': 'auc', 'model__learning_rate': 0.0025587654298097093, 'model__n_estimators': 2000, 'model__reg_alpha': 0.2133073752698083, 'model__reg_lambda': 0.5297327941936246, 'model__colsample_bytree': 0.7000000000000001, 'model__subsample': 0.30000000000000004, 'model__subsample_freq': 6, 'model__max_depth': 8, 'model__num_leaves': 144, 'model__min_child_samples': 42, 'model__cat_smooth': 121, 'model__max_bin': 1207, 'model__cat_l2': 32}. Best is trial 1 with value: 0.8931240338097627.\u001b[0m\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\u001b[32m[I 2021-03-11 23:28:01,052]\u001b[0m Trial 2 finished with value: 0.8594837231704595 and parameters: {'model__objective': 'binary', 'model__metric': 'auc', 'model__learning_rate': 0.23675373322565796, 'model__n_estimators': 2500, 'model__reg_alpha': 0.013029100715946726, 'model__reg_lambda': 0.4603952459428848, 'model__colsample_bytree': 0.8, 'model__subsample': 0.30000000000000004, 'model__subsample_freq': 1, 'model__max_depth': 24, 'model__num_leaves': 206, 'model__min_child_samples': 243, 'model__cat_smooth': 107, 'model__max_bin': 721, 'model__cat_l2': 31}. Best is trial 1 with value: 0.8931240338097627.\u001b[0m\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\u001b[32m[I 2021-03-12 00:01:50,032]\u001b[0m Trial 3 finished with value: 0.8634419760640922 and parameters: {'model__objective': 'binary', 'model__metric': 'auc', 'model__learning_rate': 0.2620292472446819, 'model__n_estimators': 4500, 'model__reg_alpha': 0.327358211179764, 'model__reg_lambda': 0.009930794645061046, 'model__colsample_bytree': 0.8, 'model__subsample': 0.4, 'model__subsample_freq': 4, 'model__max_depth': 29, 'model__num_leaves': 130, 'model__min_child_samples': 98, 'model__cat_smooth': 43, 'model__max_bin': 1871, 'model__cat_l2': 1}. Best is trial 1 with value: 0.8931240338097627.\u001b[0m\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\u001b[32m[I 2021-03-12 00:21:47,211]\u001b[0m Trial 4 finished with value: 0.8482526126021762 and parameters: {'model__objective': 'binary', 'model__metric': 'auc', 'model__learning_rate': 0.3844715422266435, 'model__n_estimators': 2500, 'model__reg_alpha': 0.0022427619428177993, 'model__reg_lambda': 0.0022498009471201555, 'model__colsample_bytree': 0.6, 'model__subsample': 0.30000000000000004, 'model__subsample_freq': 1, 'model__max_depth': 15, 'model__num_leaves': 196, 'model__min_child_samples': 94, 'model__cat_smooth': 14, 'model__max_bin': 1613, 'model__cat_l2': 27}. Best is trial 1 with value: 0.8931240338097627.\u001b[0m\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\u001b[32m[I 2021-03-12 00:30:11,594]\u001b[0m Trial 7 finished with value: 0.8916119989720116 and parameters: {'model__objective': 'binary', 'model__metric': 'auc', 'model__learning_rate': 0.003850128092851958, 'model__n_estimators': 5000, 'model__reg_alpha': 0.13595707220646971, 'model__reg_lambda': 3.8124254846872345, 'model__colsample_bytree': 0.6, 'model__subsample': 0.8, 'model__subsample_freq': 5, 'model__max_depth': 4, 'model__num_leaves': 225, 'model__min_child_samples': 67, 'model__cat_smooth': 117, 'model__max_bin': 934, 'model__cat_l2': 22}. Best is trial 1 with value: 0.8931240338097627.\u001b[0m\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\u001b[32m[I 2021-03-12 00:51:23,190]\u001b[0m Trial 6 finished with value: 0.88959021093524 and parameters: {'model__objective': 'binary', 'model__metric': 'auc', 'model__learning_rate': 0.02691740899681822, 'model__n_estimators': 3000, 'model__reg_alpha': 1.6078815373254791, 'model__reg_lambda': 0.0010898013043810827, 'model__colsample_bytree': 0.2, 'model__subsample': 0.4, 'model__subsample_freq': 9, 'model__max_depth': 27, 'model__num_leaves': 183, 'model__min_child_samples': 212, 'model__cat_smooth': 119, 'model__max_bin': 1735, 'model__cat_l2': 23}. Best is trial 1 with value: 0.8931240338097627.\u001b[0m\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "\u001b[32m[I 2021-03-12 01:24:31,223]\u001b[0m Trial 8 finished with value: 0.8904788172109024 and parameters: {'model__objective': 'binary', 'model__metric': 'auc', 'model__learning_rate': 0.001724174519716675, 'model__n_estimators': 5000, 'model__reg_alpha': 1.7495550310711316, 'model__reg_lambda': 6.790369788295345, 'model__colsample_bytree': 1.0, 'model__subsample': 0.1, 'model__subsample_freq': 9, 'model__max_depth': 31, 'model__num_leaves': 222, 'model__min_child_samples': 136, 'model__cat_smooth': 89, 'model__max_bin': 1871, 'model__cat_l2': 25}. Best is trial 1 with value: 0.8931240338097627.\u001b[0m\n",
      "\u001b[32m[I 2021-03-12 01:26:18,175]\u001b[0m Trial 9 finished with value: 0.8954349581329943 and parameters: {'model__objective': 'binary', 'model__metric': 'auc', 'model__learning_rate': 0.009542742688564705, 'model__n_estimators': 5000, 'model__reg_alpha': 0.03710762531461036, 'model__reg_lambda': 0.0526062108001846, 'model__colsample_bytree': 0.2, 'model__subsample': 0.8, 'model__subsample_freq': 8, 'model__max_depth': 8, 'model__num_leaves': 223, 'model__min_child_samples': 249, 'model__cat_smooth': 73, 'model__max_bin': 1008, 'model__cat_l2': 12}. Best is trial 9 with value: 0.8954349581329943.\u001b[0m\n",
      "\u001b[32m[I 2021-03-12 01:29:59,175]\u001b[0m Trial 5 finished with value: 0.8868334478200792 and parameters: {'model__objective': 'binary', 'model__metric': 'auc', 'model__learning_rate': 0.02746020306273221, 'model__n_estimators': 3500, 'model__reg_alpha': 0.0013232468130112403, 'model__reg_lambda': 4.576062923944523, 'model__colsample_bytree': 0.6, 'model__subsample': 0.30000000000000004, 'model__subsample_freq': 2, 'model__max_depth': 30, 'model__num_leaves': 213, 'model__min_child_samples': 3, 'model__cat_smooth': 79, 'model__max_bin': 1340, 'model__cat_l2': 11}. Best is trial 9 with value: 0.8954349581329943.\u001b[0m\n",
      "C:\\Users\\David\\anaconda3\\envs\\kaggle-env\\lib\\site-packages\\lightgbm\\basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OptunaSearchCV(estimator=Pipeline(steps=[('model',\n",
       "                                          LGBMClassifier(random_state=2021))]),\n",
       "               n_jobs=-1,\n",
       "               param_distributions={'model__cat_l2': IntUniformDistribution(high=32, low=1, step=1),\n",
       "                                    'model__cat_smooth': IntUniformDistribution(high=128, low=1, step=1),\n",
       "                                    'model__colsample_bytree': CategoricalDistribution(choices=(0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7000...\n",
       "                                    'model__reg_alpha': LogUniformDistribution(high=10.0, low=0.001),\n",
       "                                    'model__reg_lambda': LogUniformDistribution(high=10.0, low=0.001),\n",
       "                                    'model__subsample': CategoricalDistribution(choices=(0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6, 0.7000000000000001, 0.8, 0.9, 1.0)),\n",
       "                                    'model__subsample_freq': IntUniformDistribution(high=10, low=1, step=1)},\n",
       "               random_state=2021,\n",
       "               scoring=make_scorer(roc_auc_score, needs_threshold=True))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train, model__categorical_feature=list(range(len(categorical_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8956510394086716"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds = grid_search.best_estimator_.predict(X_valid)\n",
    "preds = grid_search.best_estimator_.predict_proba(X_valid)[:, 1]\n",
    "roc_auc_score(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot + variance_drop 0.8915464060319749\n",
    "# onehot 0.8970355121797735\n",
    "# codes 0.8826400343415913\n",
    "# with label encoder + categorical_feature 0.8843085347397801\n",
    "# with label codes + categorical_feature 0.8895766476594142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8954349581329943"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__objective': 'binary',\n",
       " 'model__metric': 'auc',\n",
       " 'model__learning_rate': 0.009542742688564705,\n",
       " 'model__n_estimators': 5000,\n",
       " 'model__reg_alpha': 0.03710762531461036,\n",
       " 'model__reg_lambda': 0.0526062108001846,\n",
       " 'model__colsample_bytree': 0.2,\n",
       " 'model__subsample': 0.8,\n",
       " 'model__subsample_freq': 8,\n",
       " 'model__max_depth': 8,\n",
       " 'model__num_leaves': 223,\n",
       " 'model__min_child_samples': 249,\n",
       " 'model__cat_smooth': 73,\n",
       " 'model__max_bin': 1008,\n",
       " 'model__cat_l2': 12}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 30)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.947223</td>\n",
       "      <td>0.265110</td>\n",
       "      <td>1.034602</td>\n",
       "      <td>-1.278325</td>\n",
       "      <td>-0.512837</td>\n",
       "      <td>0.250766</td>\n",
       "      <td>0.690269</td>\n",
       "      <td>0.619427</td>\n",
       "      <td>-0.174331</td>\n",
       "      <td>1.589866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.715314</td>\n",
       "      <td>1.919785</td>\n",
       "      <td>0.025815</td>\n",
       "      <td>0.154780</td>\n",
       "      <td>1.471985</td>\n",
       "      <td>-0.853928</td>\n",
       "      <td>0.688298</td>\n",
       "      <td>-0.897307</td>\n",
       "      <td>0.582567</td>\n",
       "      <td>-0.500923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat0  cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  ...     cont1  \\\n",
       "id                                                              ...             \n",
       "5      1     6     1     1     6   113     1    60    76     1  ...  0.947223   \n",
       "6      1     8     3     1     5    54     9     6    14     1  ... -0.715314   \n",
       "\n",
       "       cont2     cont3     cont4     cont5     cont6     cont7     cont8  \\\n",
       "id                                                                         \n",
       "5   0.265110  1.034602 -1.278325 -0.512837  0.250766  0.690269  0.619427   \n",
       "6   1.919785  0.025815  0.154780  1.471985 -0.853928  0.688298 -0.897307   \n",
       "\n",
       "       cont9    cont10  \n",
       "id                      \n",
       "5  -0.174331  1.589866  \n",
       "6   0.582567 -0.500923  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pd.read_csv(f\"{data_dir}/interim/test_for_David.csv\", index_col='id')\n",
    "# X_test =pd.read_parquet(f\"{data_dir}/interim/test.parq\", engine='pyarrow').convert_dtypes()\n",
    "display(X_test.shape)\n",
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = feature_engineering(X_test)\n",
    "# X_test[categorical_features] = X_test[categorical_features].apply(lambda x: x.cat.codes).astype('int').astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = grid_search.best_estimator_.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(\n",
    "    {'Id': X_test.index, 'target': preds_test})\n",
    "output.to_csv(f\"{data_dir}/processed/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
